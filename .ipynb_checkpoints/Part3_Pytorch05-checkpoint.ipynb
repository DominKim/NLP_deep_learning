{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas_profiling\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "epochs = 5\n",
    "no_cuda = False\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = glob('../data/dataset/mnist_png/training/*/*.png')[:1000]\n",
    "test_paths = glob('../data/dataset/mnist_png/testing/*/*.png')[:1000]\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_paths, transform=None):\n",
    "\n",
    "        self.data_paths = data_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.data_paths[idx]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        label = int(path.split('\\\\')[-2])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(train_paths, \n",
    "            transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(), \n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(\n",
    "                    mean=[0.406], \n",
    "                    std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(test_paths,\n",
    "           transforms.Compose([\n",
    "               transforms.ToTensor(), \n",
    "               transforms.Normalize(\n",
    "                   mean=[0.406], \n",
    "                   std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factor는 기존 값 * factor\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = \"max\", factor = 0.1, \n",
    "                              patience=0, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1000 (0%)]\tLoss: 2.255982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:628: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6679, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.630678\n",
      "Epoch     2: reducing learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "Test set: Average loss: 0.1616, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.092878\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Test set: Average loss: 0.1536, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.085043\n",
      "Epoch     4: reducing learning rate of group 0 to 1.0000e-06.\n",
      "\n",
      "Test set: Average loss: 0.1529, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.083413\n",
      "Epoch     5: reducing learning rate of group 0 to 1.0000e-07.\n",
      "\n",
      "Test set: Average loss: 0.1528, Accuracy: 980/1000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # Train Mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)  # https://pytorch.org/docs/stable/nn.html#nll-loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    # Test mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    accuracy = 100 * correct / len(test_loader.dataset)\n",
    "\n",
    "    # Learning Rate Shecduler\n",
    "    scheduler.step(accuracy, epoch)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model\n",
    "공식 홈페이지에서는 바로 다음 단계에서 배울 전체 모델을 학습하는 것보다는 이 방법을 추천 나중에 다른 모델에 적용하는거나 수정하는 등 여러가지 이유로 용이하기 대문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"model_weight.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 1.0423e-01, -8.6932e-02, -3.7515e-02,  9.4541e-02, -1.8889e-01],\n",
       "                        [ 1.2147e-01, -3.9166e-02,  1.0401e-01,  2.9271e-02, -2.4341e-02],\n",
       "                        [ 5.6292e-02,  1.1416e-02,  7.5155e-02, -7.6057e-02, -1.3538e-02],\n",
       "                        [-1.8414e-02,  2.9097e-02,  1.0178e-04,  1.7648e-01,  6.3632e-02],\n",
       "                        [-7.5931e-02, -1.2224e-01, -3.4127e-02, -8.5961e-02, -6.3418e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1639e-02,  1.2182e-01,  1.0957e-01, -1.9711e-01,  1.2181e-01],\n",
       "                        [ 5.8726e-02,  1.9345e-01,  1.3394e-01, -1.8365e-01, -1.9267e-01],\n",
       "                        [-9.3725e-02,  1.7944e-01, -3.0943e-02,  8.5518e-02, -9.4856e-02],\n",
       "                        [ 1.9855e-01, -8.1909e-02,  1.5234e-01,  3.0210e-03, -1.0633e-01],\n",
       "                        [ 1.0398e-01, -1.0484e-01,  6.0286e-02, -5.7081e-02, -2.2169e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9293e-01, -9.5742e-02,  1.0911e-01, -4.7363e-02,  2.0062e-01],\n",
       "                        [ 1.5974e-01, -9.5438e-03, -1.3292e-01,  1.2305e-01,  6.3340e-02],\n",
       "                        [-1.2971e-01,  1.2993e-01,  1.2174e-01,  1.7788e-01, -1.1183e-01],\n",
       "                        [-3.2993e-02, -4.0135e-03,  2.8882e-02, -1.5245e-01, -1.4245e-01],\n",
       "                        [ 1.0883e-01, -4.7270e-02,  9.6955e-02,  1.0643e-02,  6.5275e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.1339e-02,  7.0423e-02,  9.7676e-02, -1.8625e-01,  1.0124e-01],\n",
       "                        [-1.4596e-01, -1.5590e-01,  9.6963e-03, -3.4746e-02,  1.1839e-01],\n",
       "                        [-1.2199e-01, -1.8340e-01,  1.4267e-01, -3.1064e-02,  1.1216e-01],\n",
       "                        [ 5.9015e-02, -1.5495e-01,  3.6726e-02,  4.5128e-02, -1.3707e-01],\n",
       "                        [-9.9392e-02,  6.4306e-02,  3.2252e-02, -8.9177e-02, -6.4961e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8432e-01, -3.5113e-02,  1.1485e-01,  8.7582e-02, -1.3024e-01],\n",
       "                        [-1.6803e-01,  1.9628e-01,  1.4070e-02,  1.3858e-01,  4.0620e-02],\n",
       "                        [ 6.7587e-02,  1.5497e-01,  1.9435e-01, -1.3175e-01,  2.3798e-02],\n",
       "                        [ 1.5217e-01,  1.4996e-01,  1.2845e-01, -1.4433e-01, -1.4568e-01],\n",
       "                        [-1.1999e-01,  2.8072e-02,  2.0230e-01, -1.2576e-01,  1.0557e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1246e-01, -1.8895e-01, -4.0748e-02,  1.1900e-01,  1.8886e-01],\n",
       "                        [-1.2518e-01,  4.4065e-02,  1.7547e-01,  1.3643e-01,  1.2786e-01],\n",
       "                        [ 1.4220e-01,  1.2813e-01,  5.4676e-02, -1.3368e-01, -1.6618e-01],\n",
       "                        [-9.1977e-02, -2.2241e-02, -1.2057e-01,  7.5750e-02,  6.3263e-02],\n",
       "                        [-4.6565e-02,  7.6615e-02,  6.5276e-02,  1.2351e-01,  1.3586e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.9286e-02,  1.9415e-01, -2.3844e-02, -7.0996e-03, -1.8882e-01],\n",
       "                        [-1.3031e-01, -1.1827e-01, -8.6471e-02,  1.4197e-01, -6.5170e-02],\n",
       "                        [-1.5066e-01,  7.5895e-02,  6.3382e-02,  1.2942e-01, -1.0320e-01],\n",
       "                        [ 4.2684e-02, -7.3201e-02, -4.5163e-02, -1.5939e-01, -9.0377e-02],\n",
       "                        [-6.1559e-02,  8.5756e-02,  3.7124e-02,  5.0273e-02,  2.0124e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9665e-01,  1.3617e-01,  3.8314e-03, -1.4167e-01,  1.5300e-01],\n",
       "                        [-4.8185e-02, -1.6822e-02, -1.7518e-01, -4.2690e-02, -1.3204e-01],\n",
       "                        [ 1.8591e-01, -1.7367e-01, -1.5837e-01, -9.4726e-03, -1.1069e-01],\n",
       "                        [ 7.3309e-02, -7.6742e-02, -9.5013e-02,  9.8415e-03,  1.4305e-01],\n",
       "                        [-1.3989e-01,  9.4926e-02,  1.2906e-01,  1.9543e-01, -1.4128e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.7075e-02, -1.4878e-01,  1.7149e-01, -7.5966e-02,  1.2262e-01],\n",
       "                        [ 5.1513e-03, -1.5995e-02, -5.7370e-03,  3.6416e-02,  9.7394e-02],\n",
       "                        [ 3.2359e-02,  6.1375e-02, -1.7987e-01,  1.4798e-01,  1.7767e-01],\n",
       "                        [ 1.6622e-01,  1.4859e-01, -1.4494e-01, -7.3546e-02,  1.7871e-01],\n",
       "                        [-1.5228e-01,  1.8159e-01, -1.5858e-01, -1.4188e-01,  9.8495e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4773e-01, -4.7394e-02,  1.4748e-01,  1.6148e-01,  1.9114e-01],\n",
       "                        [-4.4636e-02, -1.5756e-01,  1.9821e-01, -4.0916e-02, -8.2208e-02],\n",
       "                        [ 4.4984e-02, -1.4235e-01,  1.3132e-01,  1.2533e-01, -1.6055e-01],\n",
       "                        [-1.6814e-01, -2.0642e-02,  8.1945e-02, -7.8337e-03, -1.0364e-01],\n",
       "                        [ 1.0251e-03, -1.9187e-01, -1.4500e-01, -1.3620e-01,  1.6329e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.7679e-01, -6.7636e-02,  8.9261e-03,  8.8864e-02,  2.3682e-02],\n",
       "                        [-9.9767e-02,  1.1537e-01,  1.2257e-01, -1.2221e-02, -2.5053e-02],\n",
       "                        [ 1.8195e-01,  1.7462e-01, -1.1399e-01,  1.9495e-01,  4.9059e-02],\n",
       "                        [-1.3268e-01,  1.0930e-01, -1.4989e-01,  1.8405e-01, -1.2899e-01],\n",
       "                        [ 5.6733e-02,  6.0684e-02,  4.7096e-02,  1.6520e-01, -8.3485e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.7459e-02, -1.7555e-01, -9.3707e-03, -9.5668e-02,  7.0162e-03],\n",
       "                        [-4.4592e-02,  6.4356e-02,  1.7301e-01,  5.9565e-02, -6.4676e-02],\n",
       "                        [-1.0229e-01, -1.7718e-01,  1.6849e-01, -3.6944e-02,  4.0652e-02],\n",
       "                        [ 3.3938e-03, -1.3037e-01,  1.1229e-01,  1.1261e-01,  9.6732e-03],\n",
       "                        [-1.1716e-01, -8.7376e-02,  1.7441e-03, -1.1530e-01, -1.1332e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0596e-02, -5.7844e-02,  4.9701e-02, -5.1808e-02, -2.5924e-02],\n",
       "                        [-7.7714e-02, -1.8386e-01,  1.7484e-01,  3.9717e-02,  1.8108e-01],\n",
       "                        [-3.3964e-02, -5.1755e-02, -1.8857e-01, -7.4497e-02,  1.3392e-01],\n",
       "                        [-1.9771e-01, -7.1364e-02,  1.2150e-01,  1.1636e-01,  7.6097e-02],\n",
       "                        [-4.1039e-02, -1.6290e-02, -3.8664e-02, -7.3812e-02,  8.4346e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.8329e-02, -1.1281e-01,  4.4560e-02, -1.4639e-01, -4.4709e-02],\n",
       "                        [ 1.0184e-01,  7.3893e-02,  1.6905e-01, -1.3833e-01, -1.8323e-04],\n",
       "                        [-6.0586e-02, -1.1440e-01, -1.1511e-01,  4.8424e-02,  1.9324e-02],\n",
       "                        [-1.0469e-01, -1.4474e-01, -1.6947e-01,  1.9366e-01, -3.5780e-02],\n",
       "                        [-4.9078e-02, -7.7396e-02, -1.0404e-01, -1.8610e-01, -1.1943e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2428e-01,  4.5940e-02, -6.9044e-02, -7.4512e-02,  1.2890e-01],\n",
       "                        [ 1.4539e-01,  1.9427e-01,  5.9888e-02,  9.8266e-02, -1.4649e-02],\n",
       "                        [-1.1776e-01, -1.9666e-01,  1.2235e-01, -2.7914e-02,  8.3424e-02],\n",
       "                        [ 7.9162e-03, -1.8879e-01, -9.9319e-02,  5.6326e-02, -3.9887e-02],\n",
       "                        [-1.9544e-01,  6.7923e-02,  5.8077e-03, -6.5343e-02,  8.0690e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2048e-02, -7.4073e-02,  1.7987e-01,  1.0028e-01,  2.4394e-02],\n",
       "                        [-3.8104e-02, -1.6910e-01,  1.5527e-01, -5.1364e-02, -1.2994e-01],\n",
       "                        [ 1.2936e-01,  7.2831e-02,  5.1238e-02, -3.8731e-02, -6.2502e-02],\n",
       "                        [ 3.5098e-02,  1.5718e-01,  3.1218e-02, -9.2769e-02,  1.9967e-01],\n",
       "                        [ 4.8031e-03,  1.6013e-01,  5.1236e-02,  1.8153e-01,  1.1674e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0251e-01,  1.3986e-01,  7.9757e-04, -1.6090e-01, -4.2038e-02],\n",
       "                        [-1.8096e-01, -1.0432e-01, -1.4244e-01,  1.3627e-01, -4.2063e-02],\n",
       "                        [-3.5037e-02,  9.5001e-02,  8.0390e-02, -1.3247e-01,  7.3873e-02],\n",
       "                        [ 8.4353e-02, -1.5993e-01,  1.7303e-01, -1.2191e-01, -7.7687e-02],\n",
       "                        [-1.6526e-01,  1.8202e-01,  3.7558e-02,  1.6859e-01,  1.4156e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0859e-01, -6.4209e-02, -1.6032e-01,  3.0730e-02, -1.9596e-02],\n",
       "                        [-2.0643e-02, -9.8671e-02,  3.5241e-03,  5.6556e-02,  7.0956e-02],\n",
       "                        [-1.6183e-01,  9.6054e-02,  1.9914e-02,  1.3732e-01,  1.4070e-01],\n",
       "                        [-1.5808e-01,  1.9146e-01, -1.9748e-01,  1.1430e-01,  1.3754e-02],\n",
       "                        [ 9.4978e-02, -1.0837e-01,  1.1992e-01, -9.9417e-02, -1.7707e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5817e-02,  1.0901e-01,  1.9850e-01, -2.0354e-02,  1.9296e-01],\n",
       "                        [ 1.2714e-01, -9.9872e-02, -1.5419e-01,  1.1270e-01, -1.0905e-01],\n",
       "                        [ 9.0473e-02, -1.7219e-01,  1.4577e-01,  6.0349e-02, -2.2714e-02],\n",
       "                        [ 9.0649e-02, -1.4322e-01, -4.3742e-02,  2.1920e-03, -1.1569e-01],\n",
       "                        [-5.1705e-02, -8.6624e-02,  1.9080e-01,  1.6996e-01,  1.7195e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6293e-01, -1.9197e-01,  6.8057e-02,  7.5710e-02, -1.4566e-01],\n",
       "                        [ 7.9764e-02, -1.0916e-01,  3.3440e-02,  6.9537e-02,  1.7585e-01],\n",
       "                        [-1.0680e-01, -1.5818e-01,  1.8667e-01,  8.7000e-02,  1.0066e-01],\n",
       "                        [ 7.1075e-02, -7.1309e-02,  1.2072e-01, -1.7362e-01,  2.9865e-02],\n",
       "                        [ 9.0048e-02,  1.3661e-01, -1.0053e-01, -1.3588e-01,  7.5473e-02]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.1577, -0.1644, -0.1794, -0.0931, -0.0357, -0.1164, -0.0842, -0.1752,\n",
       "                       0.1253, -0.0421, -0.1267,  0.0549, -0.1480,  0.1424,  0.1163, -0.1953,\n",
       "                      -0.1573, -0.1318, -0.1087,  0.0271])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-4.4318e-02, -3.3292e-02,  2.0265e-02, -1.4715e-02, -1.7923e-02],\n",
       "                        [-3.7047e-02,  1.8201e-02,  3.2886e-03, -1.7184e-02, -2.7336e-02],\n",
       "                        [ 9.5275e-03,  1.2468e-02,  2.0377e-02,  1.3842e-02, -6.3650e-03],\n",
       "                        [-3.4503e-02,  2.8780e-02,  2.5307e-04, -2.8892e-02,  3.9303e-02],\n",
       "                        [ 2.4819e-02, -3.5097e-02, -2.2064e-02, -1.4860e-02, -2.5561e-02]],\n",
       "              \n",
       "                       [[ 2.0699e-02, -3.1778e-02,  4.2144e-02, -1.8296e-02,  2.6087e-02],\n",
       "                        [ 1.0941e-03, -1.9462e-02,  3.0760e-02, -3.3841e-02, -2.3748e-02],\n",
       "                        [ 4.9988e-03,  3.5796e-02, -1.8166e-02, -2.6567e-02, -2.8407e-02],\n",
       "                        [-2.0005e-02, -1.5123e-02, -9.4247e-03, -2.4682e-02,  1.4055e-02],\n",
       "                        [ 1.1253e-04, -2.8922e-02, -2.4810e-02,  9.6924e-03, -9.1085e-04]],\n",
       "              \n",
       "                       [[ 3.1394e-02, -6.6553e-03, -3.6098e-02, -3.3097e-02, -1.3078e-02],\n",
       "                        [-1.0019e-02,  5.4499e-03, -9.8005e-03,  1.6762e-02, -1.4651e-02],\n",
       "                        [ 3.3137e-02,  1.0904e-02, -1.3038e-02,  4.0433e-02,  1.1720e-02],\n",
       "                        [-2.9965e-02, -2.3988e-02,  2.8882e-02,  2.0799e-02,  3.5147e-02],\n",
       "                        [-2.9700e-03,  3.1975e-02,  2.2613e-02,  1.3812e-02, -1.0472e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0639e-03, -3.1446e-02,  2.0999e-03, -1.2935e-02,  1.5930e-02],\n",
       "                        [ 3.8204e-02, -2.4021e-02,  2.2036e-03,  4.3977e-02, -3.5448e-02],\n",
       "                        [-7.1071e-03,  4.4311e-02,  3.2183e-02,  1.3595e-02, -1.8982e-02],\n",
       "                        [-3.5064e-03, -3.9029e-02, -4.1221e-02, -4.1402e-02,  4.3361e-02],\n",
       "                        [ 3.5779e-02,  1.8185e-02, -1.1168e-02,  3.8554e-02, -1.1697e-02]],\n",
       "              \n",
       "                       [[ 3.1081e-02, -1.2801e-03, -2.1279e-02, -1.2760e-02, -9.8598e-03],\n",
       "                        [-4.0901e-02,  1.3564e-02, -1.3647e-02,  2.0340e-02,  2.8279e-02],\n",
       "                        [-7.0822e-03,  2.2008e-02,  9.1598e-03,  3.0147e-02, -2.8682e-02],\n",
       "                        [-3.9261e-03, -1.4617e-02,  3.9360e-02, -3.9812e-02, -2.4716e-02],\n",
       "                        [ 5.0928e-03,  3.9978e-02,  3.0491e-02, -4.1556e-02, -3.1054e-02]],\n",
       "              \n",
       "                       [[ 4.3120e-02,  6.3988e-03, -3.8379e-02, -1.4181e-02,  1.9461e-02],\n",
       "                        [-9.1943e-03, -3.4014e-02, -2.7402e-02, -2.2749e-02, -1.5482e-03],\n",
       "                        [ 1.7933e-02,  2.2246e-02, -2.0849e-02, -6.8173e-03, -3.4028e-02],\n",
       "                        [ 3.4222e-02,  4.5513e-02,  4.4311e-02,  1.8899e-02, -9.0116e-03],\n",
       "                        [-1.0397e-03,  1.6402e-02, -3.8697e-02,  2.9080e-03, -3.6193e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.4937e-02, -1.4772e-03, -1.4096e-02, -2.8099e-02,  7.4862e-03],\n",
       "                        [ 1.6029e-03,  6.8952e-03, -2.4752e-02, -4.3472e-02,  1.2508e-03],\n",
       "                        [-1.8517e-02, -1.5179e-02,  3.3157e-02,  7.8526e-03,  2.1032e-02],\n",
       "                        [-1.2698e-02, -3.5774e-02,  8.7398e-03, -2.9445e-02,  6.0532e-03],\n",
       "                        [-3.5125e-02,  3.3409e-02, -3.0785e-02,  3.8681e-02,  3.1642e-02]],\n",
       "              \n",
       "                       [[ 3.3187e-02,  2.6804e-02,  1.0841e-02, -1.8014e-03, -6.5828e-04],\n",
       "                        [-1.8307e-02, -4.1279e-02,  4.1069e-02,  2.5403e-03,  2.1279e-02],\n",
       "                        [ 1.2865e-03,  1.2422e-02, -2.7638e-02, -3.4707e-02,  3.4438e-02],\n",
       "                        [ 1.6719e-02,  2.1559e-02, -4.4926e-02,  2.9045e-03, -4.1414e-02],\n",
       "                        [-5.4005e-03, -2.9029e-03, -3.1808e-02, -4.4349e-02,  7.1380e-04]],\n",
       "              \n",
       "                       [[ 4.0287e-02,  4.0580e-02, -2.6996e-02, -7.9600e-03, -3.7481e-02],\n",
       "                        [-3.4825e-02, -1.2037e-02,  4.3545e-02, -1.1652e-02,  2.5084e-03],\n",
       "                        [ 4.2137e-02,  8.1251e-03,  3.6160e-02,  2.9831e-02,  4.2080e-02],\n",
       "                        [ 7.4334e-03, -3.6236e-02, -3.8319e-02, -2.2789e-02,  3.7481e-02],\n",
       "                        [ 2.5190e-02,  1.2810e-02, -3.3927e-02, -3.2570e-02,  3.6950e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.1795e-02, -1.8017e-02,  1.7960e-02, -2.6501e-02, -1.3924e-02],\n",
       "                        [ 5.0640e-04,  2.7401e-02,  2.5554e-02, -3.7451e-03, -1.2547e-02],\n",
       "                        [-7.2633e-04,  2.3363e-02, -3.7419e-02, -1.3076e-02, -4.2611e-02],\n",
       "                        [ 6.1424e-03, -5.3717e-03,  2.5620e-02,  3.6382e-02, -3.7391e-02],\n",
       "                        [-2.0202e-02, -7.3113e-03, -2.8279e-04, -9.9184e-03, -2.7747e-02]],\n",
       "              \n",
       "                       [[-1.7458e-02, -1.0046e-03,  3.6100e-02, -1.1184e-02,  2.9485e-02],\n",
       "                        [-3.6439e-02,  2.0464e-03, -3.4614e-02, -4.1569e-02,  4.6875e-03],\n",
       "                        [-2.0774e-02,  3.2777e-02,  3.5520e-02, -4.4146e-02, -2.5934e-03],\n",
       "                        [-7.8891e-03, -2.5648e-02, -3.1162e-02, -1.8585e-02,  2.0314e-02],\n",
       "                        [ 1.0499e-02,  2.6886e-02, -2.6826e-03,  2.3502e-02,  9.0802e-03]],\n",
       "              \n",
       "                       [[-9.6734e-03, -2.4210e-03, -4.0400e-02, -8.8327e-04, -1.4770e-02],\n",
       "                        [-1.4864e-02, -1.7630e-02, -9.4530e-03, -3.2611e-02,  2.7774e-03],\n",
       "                        [-1.9250e-03, -1.1569e-02,  3.9289e-02,  3.0668e-02,  1.3204e-02],\n",
       "                        [-1.6849e-02,  5.4351e-03, -3.0542e-02,  3.1809e-02,  4.2713e-02],\n",
       "                        [-7.1266e-03,  3.4159e-02,  4.2000e-02, -2.3662e-03, -1.6175e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9192e-03,  7.9825e-03, -4.0710e-02, -1.8194e-03, -1.5216e-02],\n",
       "                        [ 3.0403e-02, -5.7689e-04,  3.0300e-02,  4.0776e-02, -1.3021e-02],\n",
       "                        [ 1.0001e-02, -3.1602e-03, -1.8535e-02, -2.3664e-02,  2.3630e-03],\n",
       "                        [ 1.4138e-02, -7.1316e-03,  8.6283e-03,  2.9081e-02,  1.9806e-02],\n",
       "                        [ 1.8961e-02,  1.3312e-02, -3.3301e-02, -2.5774e-02, -3.2237e-02]],\n",
       "              \n",
       "                       [[ 3.0610e-02, -3.8094e-02, -3.1228e-02,  3.2810e-02,  2.8971e-02],\n",
       "                        [-4.1492e-02,  2.7538e-02, -7.6599e-03,  1.3135e-02, -2.5674e-02],\n",
       "                        [-6.1176e-03,  1.1350e-02,  3.6809e-02,  3.0498e-02, -2.2486e-02],\n",
       "                        [-2.8740e-02, -1.6491e-03,  1.6649e-02,  2.7605e-02, -4.3321e-02],\n",
       "                        [-3.2849e-03,  2.3298e-03, -1.8580e-02,  3.8076e-02, -1.0946e-02]],\n",
       "              \n",
       "                       [[-4.2107e-02, -2.5464e-02,  3.2711e-03, -3.1691e-02,  1.1117e-02],\n",
       "                        [ 4.4199e-02,  3.0824e-03, -9.2673e-03,  4.3506e-02,  3.3700e-02],\n",
       "                        [ 3.0435e-02,  4.4990e-03,  3.7432e-03, -3.3634e-02,  5.1751e-03],\n",
       "                        [ 4.4054e-02,  3.5163e-03, -3.8376e-02,  2.5534e-02,  4.1015e-02],\n",
       "                        [ 3.8047e-02,  3.2743e-03,  9.7820e-03,  7.9450e-03, -1.7651e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.2958e-04,  3.5387e-03, -3.6820e-02,  3.8588e-02, -1.6223e-02],\n",
       "                        [-3.5057e-02,  8.7772e-04, -3.7676e-02,  6.6744e-03, -2.8131e-02],\n",
       "                        [-8.7647e-03, -1.1585e-02,  3.4172e-02,  3.5717e-02,  4.5425e-02],\n",
       "                        [ 5.9926e-03,  3.0225e-02, -3.5343e-02, -2.9119e-02,  2.5392e-02],\n",
       "                        [ 1.0758e-02,  1.4077e-02,  2.6826e-02,  2.9021e-02,  2.1616e-02]],\n",
       "              \n",
       "                       [[-1.5639e-02, -1.2921e-02,  1.1110e-02,  3.8144e-02, -2.3664e-03],\n",
       "                        [-1.2372e-02,  2.6222e-02,  3.1577e-02,  4.6171e-04, -1.2116e-02],\n",
       "                        [-4.3775e-02,  4.2948e-03,  1.5338e-02, -3.2092e-02, -3.2516e-02],\n",
       "                        [-4.4144e-02,  3.6401e-02,  4.3459e-02,  4.4900e-02,  4.0348e-02],\n",
       "                        [-4.1394e-03,  2.1139e-02,  2.7719e-02, -1.1352e-02, -2.5386e-02]],\n",
       "              \n",
       "                       [[ 3.8206e-02, -3.1697e-03,  1.8381e-02, -1.9421e-02, -2.1731e-02],\n",
       "                        [-7.0702e-03,  2.9187e-03,  2.8136e-02,  3.0562e-02, -4.5322e-03],\n",
       "                        [ 4.5040e-02, -2.2335e-02,  4.7903e-03, -2.6573e-02,  8.5268e-03],\n",
       "                        [ 4.1666e-02, -3.5446e-02,  1.1962e-02, -3.9914e-02, -8.6089e-03],\n",
       "                        [-2.0241e-02,  1.5705e-03, -2.9610e-02,  1.2116e-02, -4.1634e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7006e-02,  4.3417e-02, -2.9723e-02, -2.1845e-02,  3.9877e-02],\n",
       "                        [-7.0427e-05,  2.6522e-02, -4.1717e-02, -1.6149e-02,  2.2026e-02],\n",
       "                        [ 2.4181e-02, -4.0900e-02,  1.2541e-02, -1.7586e-02, -1.8773e-02],\n",
       "                        [-2.4004e-02, -3.8529e-02, -3.2922e-02,  1.5335e-03,  3.5152e-03],\n",
       "                        [ 3.1183e-02,  3.6899e-02,  1.5879e-02,  3.0373e-02,  1.7493e-03]],\n",
       "              \n",
       "                       [[-3.8444e-03,  2.4663e-02, -2.7717e-02, -6.9600e-03, -4.0400e-02],\n",
       "                        [-1.9589e-02, -1.7026e-02, -1.7864e-02,  3.0814e-03, -7.3357e-03],\n",
       "                        [ 9.7334e-03, -6.6989e-03,  4.3226e-02, -1.1677e-03,  3.6027e-02],\n",
       "                        [ 1.4131e-02,  1.6715e-02, -1.2150e-02, -1.9498e-02, -5.6231e-04],\n",
       "                        [ 5.2698e-03,  1.4739e-02,  1.4407e-03, -1.2446e-02,  1.2783e-02]],\n",
       "              \n",
       "                       [[ 2.8171e-02, -3.1991e-02, -3.7207e-02,  9.8242e-03, -4.3314e-02],\n",
       "                        [-3.0513e-02,  7.6305e-03,  1.7806e-02, -3.6198e-02,  2.9501e-02],\n",
       "                        [-1.8230e-02,  3.6232e-02, -1.9115e-03, -3.5406e-02, -1.5342e-02],\n",
       "                        [-4.2913e-02,  1.4912e-02, -4.4956e-03,  4.2475e-02,  2.8757e-02],\n",
       "                        [ 3.9117e-02,  3.0294e-02,  1.7658e-02,  2.5611e-02,  3.6370e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.8510e-03,  1.2666e-02,  2.4862e-02,  9.1038e-03,  1.7749e-02],\n",
       "                        [ 2.0585e-02, -4.2359e-02,  7.4929e-03,  6.7091e-03, -2.7208e-02],\n",
       "                        [ 4.3561e-02, -3.0427e-02,  4.0754e-02, -8.6171e-03, -3.3030e-02],\n",
       "                        [-1.0835e-03,  2.8204e-03,  3.9107e-02, -2.9257e-02,  3.6022e-02],\n",
       "                        [-4.3128e-02,  7.8548e-03,  4.2522e-02,  2.5389e-03,  1.9913e-02]],\n",
       "              \n",
       "                       [[-2.6043e-02,  1.4787e-03,  1.6848e-02,  4.7582e-04,  1.8276e-02],\n",
       "                        [-3.0149e-02,  2.1752e-03, -8.0882e-03, -1.1582e-02,  5.8632e-03],\n",
       "                        [-1.0015e-02,  1.9139e-02, -1.8196e-03, -1.4150e-02,  1.8063e-02],\n",
       "                        [ 3.4392e-02, -2.5945e-02, -1.3829e-02,  1.1538e-02, -3.0901e-02],\n",
       "                        [-3.8921e-02,  3.1607e-02, -4.3916e-02,  1.0306e-02,  3.0713e-03]],\n",
       "              \n",
       "                       [[ 4.4678e-02, -1.4334e-02, -2.7187e-02,  3.7252e-02,  1.5992e-02],\n",
       "                        [ 4.2500e-02, -6.6571e-03,  3.4690e-02,  4.0688e-02,  3.6937e-02],\n",
       "                        [-2.5096e-02,  4.4249e-02, -3.2678e-02, -6.7919e-03,  4.8522e-03],\n",
       "                        [ 1.8194e-02,  3.4425e-02, -3.6312e-02,  4.2604e-02,  5.5932e-03],\n",
       "                        [ 3.5264e-02,  1.2084e-03,  3.9430e-02, -3.8952e-02,  3.4787e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.0901e-03, -3.5250e-02,  3.1562e-02,  2.3440e-02, -4.1016e-03],\n",
       "                        [-3.6390e-02,  1.1766e-02,  2.7737e-02, -3.9410e-02,  8.9857e-03],\n",
       "                        [ 4.4161e-02,  2.6473e-02,  1.6393e-02,  4.0678e-02, -1.1809e-02],\n",
       "                        [-1.6999e-02,  2.1845e-02, -2.9384e-02,  1.8337e-02,  7.7703e-03],\n",
       "                        [-2.0035e-02,  2.3349e-02,  3.0839e-02, -3.9916e-02,  3.6817e-02]],\n",
       "              \n",
       "                       [[ 1.0278e-02,  1.2917e-02,  1.9823e-02,  3.0526e-02,  5.3457e-03],\n",
       "                        [-1.1055e-02,  3.5629e-02,  4.4525e-02, -3.9807e-02, -3.7788e-02],\n",
       "                        [ 2.1805e-02,  1.4591e-02,  3.5569e-02, -1.5901e-02,  4.2661e-02],\n",
       "                        [ 1.1307e-03,  2.5456e-02,  9.1178e-03, -2.8889e-02,  1.8361e-02],\n",
       "                        [-4.0470e-02,  3.8789e-02, -2.9552e-02,  2.0488e-02, -1.5711e-02]],\n",
       "              \n",
       "                       [[-7.2844e-03, -8.3403e-03,  2.2336e-02,  3.3471e-02, -1.3357e-03],\n",
       "                        [-9.9723e-03, -2.3697e-02,  1.9513e-02, -3.3771e-03, -3.3827e-02],\n",
       "                        [-2.3061e-02, -1.4588e-02, -2.8494e-02,  3.7332e-02, -3.2462e-02],\n",
       "                        [ 8.9485e-03, -5.4110e-03, -4.2038e-02,  1.8129e-02, -6.0092e-03],\n",
       "                        [ 1.9659e-02,  8.5144e-03, -2.9893e-02, -3.2107e-02,  4.1548e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.5592e-02, -2.1730e-02,  1.8895e-02,  2.5116e-03, -2.9241e-02],\n",
       "                        [ 2.5811e-02,  3.5770e-02,  8.2320e-03,  1.7185e-02, -3.5244e-02],\n",
       "                        [-1.8947e-02, -2.8284e-02, -5.0799e-03, -4.0288e-02,  4.4124e-02],\n",
       "                        [-5.8668e-03, -3.4916e-02,  3.8314e-02, -1.7195e-02, -3.4729e-02],\n",
       "                        [-3.1430e-02, -2.4788e-02, -2.6769e-02,  1.8939e-02, -4.3783e-02]],\n",
       "              \n",
       "                       [[-1.8909e-02, -4.3056e-03, -2.2022e-02,  4.3965e-02,  4.3059e-02],\n",
       "                        [ 2.0394e-03, -1.6850e-02,  4.4910e-02, -4.1661e-02, -1.4618e-02],\n",
       "                        [ 3.1107e-02,  4.3687e-02, -3.4596e-02, -1.6373e-02,  1.2504e-02],\n",
       "                        [-3.8065e-02,  3.8888e-02,  2.5704e-02,  2.3690e-02, -1.6272e-02],\n",
       "                        [-2.8692e-02,  3.0549e-02, -1.2593e-02,  6.6611e-03,  1.7102e-02]],\n",
       "              \n",
       "                       [[-2.4350e-02,  2.8689e-03, -2.8329e-02, -7.1122e-03, -7.1179e-03],\n",
       "                        [-3.4615e-02,  3.0508e-02, -4.3021e-02, -2.7789e-02, -8.7377e-04],\n",
       "                        [-1.1464e-02, -3.1128e-02, -3.9519e-02,  3.9507e-02, -3.4079e-03],\n",
       "                        [-3.4594e-02,  8.7503e-03, -3.1220e-02,  8.2306e-03, -7.1964e-03],\n",
       "                        [ 1.6230e-03,  4.1562e-02,  2.8109e-02,  1.1582e-02, -3.4415e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8453e-02, -5.3799e-03,  3.7858e-02,  2.8205e-02, -3.9058e-02],\n",
       "                        [ 2.2696e-02,  3.4753e-02, -3.1235e-02,  5.7770e-04, -6.5223e-03],\n",
       "                        [-3.3799e-02, -1.9646e-02, -2.2309e-02, -3.8303e-02, -8.6636e-03],\n",
       "                        [ 6.2618e-03,  4.2590e-02, -2.6473e-02,  1.1319e-02,  3.8866e-02],\n",
       "                        [-2.8881e-03, -6.6386e-03,  3.7281e-02, -2.6206e-02,  1.9238e-02]],\n",
       "              \n",
       "                       [[ 1.2377e-02,  2.5754e-02,  9.2653e-04,  1.8816e-02, -2.2740e-02],\n",
       "                        [-3.0936e-02,  3.3887e-02, -3.0702e-02, -1.7602e-02, -2.0341e-02],\n",
       "                        [-1.7955e-03,  1.4597e-02,  3.6979e-02, -1.1461e-02, -2.2001e-02],\n",
       "                        [ 3.4901e-02, -9.2365e-03,  6.3276e-03, -1.5452e-02,  2.8061e-02],\n",
       "                        [-2.4263e-02, -1.1431e-02, -3.1856e-02, -1.5535e-02,  1.2671e-02]],\n",
       "              \n",
       "                       [[-2.8972e-02, -1.6267e-02,  4.5313e-02,  1.9799e-02, -3.1880e-02],\n",
       "                        [ 2.3143e-03,  1.5459e-02,  1.6927e-02, -3.1769e-02,  4.4140e-02],\n",
       "                        [ 1.1223e-03, -2.9489e-02, -3.7694e-02, -8.9210e-03, -1.5308e-02],\n",
       "                        [ 2.5506e-02,  2.8635e-02, -3.9135e-02, -3.9261e-02, -4.3174e-02],\n",
       "                        [-3.3983e-02, -2.2006e-02, -4.2074e-02,  1.5971e-02,  1.6266e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.6626e-02, -2.7551e-02, -1.0790e-02,  3.9717e-02,  6.9241e-03],\n",
       "                        [ 1.7398e-02, -1.8622e-02, -5.0916e-03, -1.1218e-02,  3.2255e-02],\n",
       "                        [-4.1026e-02,  3.5584e-03,  7.2172e-03, -2.4271e-02,  1.3026e-02],\n",
       "                        [-3.4043e-02,  7.1429e-03, -5.0741e-03, -3.3618e-02,  1.1441e-02],\n",
       "                        [ 2.5724e-02, -9.2361e-03,  2.3967e-02,  4.2019e-02,  1.0459e-03]],\n",
       "              \n",
       "                       [[ 3.0035e-02,  3.1891e-02, -3.3535e-02, -3.8180e-02, -3.2100e-02],\n",
       "                        [ 4.6568e-03, -1.7593e-02,  3.5081e-02, -3.6151e-03, -2.2401e-02],\n",
       "                        [ 2.4885e-02,  4.2409e-02, -1.5584e-02, -2.9756e-02, -2.1573e-02],\n",
       "                        [ 3.4859e-02,  2.3549e-02, -2.1064e-02,  9.5780e-03, -2.6821e-02],\n",
       "                        [ 3.6744e-02,  2.5918e-02,  2.7958e-02, -1.4272e-02,  2.9142e-02]],\n",
       "              \n",
       "                       [[ 3.5175e-02,  3.6750e-02,  3.1385e-02, -1.8724e-02,  3.5845e-02],\n",
       "                        [-3.9328e-02,  4.3884e-02, -2.0807e-02, -2.7281e-02, -2.8220e-02],\n",
       "                        [ 2.9112e-03,  2.5772e-02,  3.2780e-02, -1.3227e-02,  4.0523e-03],\n",
       "                        [-2.6965e-02,  2.7138e-03,  2.5190e-02, -2.5120e-02,  1.4667e-02],\n",
       "                        [ 4.1966e-02,  2.6424e-02,  1.4592e-02,  1.3811e-02,  4.2741e-02]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([-0.0196, -0.0194,  0.0464,  0.0147, -0.0326, -0.0313,  0.0191, -0.0185,\n",
       "                       0.0278,  0.0281, -0.0299, -0.0378, -0.0074, -0.0020,  0.0013, -0.0167,\n",
       "                       0.0370, -0.0296, -0.0250, -0.0097,  0.0313,  0.0221,  0.0042,  0.0136,\n",
       "                      -0.0234, -0.0017, -0.0102,  0.0418,  0.0235, -0.0053,  0.0117, -0.0129,\n",
       "                       0.0069, -0.0267, -0.0135,  0.0401,  0.0036, -0.0064, -0.0285, -0.0074,\n",
       "                       0.0240,  0.0408,  0.0156,  0.0107, -0.0303,  0.0390,  0.0255, -0.0229,\n",
       "                      -0.0107, -0.0385])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0276, -0.0283, -0.0183,  ...,  0.0244, -0.0222,  0.0164],\n",
       "                      [-0.0232, -0.0053, -0.0144,  ...,  0.0226, -0.0190,  0.0011],\n",
       "                      [ 0.0081, -0.0049, -0.0149,  ...,  0.0163,  0.0161,  0.0241],\n",
       "                      ...,\n",
       "                      [-0.0107,  0.0097,  0.0071,  ...,  0.0112, -0.0209,  0.0231],\n",
       "                      [ 0.0004,  0.0230, -0.0060,  ..., -0.0220,  0.0132,  0.0303],\n",
       "                      [-0.0126,  0.0300, -0.0215,  ..., -0.0146,  0.0351, -0.0334]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0201,  0.0020,  0.0340,  0.0114,  0.0207,  0.0066,  0.0301,  0.0141,\n",
       "                       0.0253,  0.0131,  0.0238, -0.0272, -0.0170,  0.0065, -0.0274, -0.0082,\n",
       "                      -0.0032, -0.0085,  0.0277,  0.0078,  0.0323,  0.0060, -0.0232,  0.0279,\n",
       "                       0.0111, -0.0279,  0.0122,  0.0335,  0.0325,  0.0231, -0.0016, -0.0284,\n",
       "                      -0.0177,  0.0082, -0.0131,  0.0046, -0.0202,  0.0051,  0.0175, -0.0101,\n",
       "                       0.0266, -0.0210,  0.0196,  0.0323,  0.0034,  0.0094, -0.0217,  0.0241,\n",
       "                       0.0138, -0.0239,  0.0237,  0.0259, -0.0304,  0.0141, -0.0108,  0.0153,\n",
       "                      -0.0150, -0.0289, -0.0323,  0.0316, -0.0050, -0.0150,  0.0195, -0.0140,\n",
       "                      -0.0175,  0.0096, -0.0111, -0.0137,  0.0144, -0.0160, -0.0041,  0.0265,\n",
       "                       0.0131, -0.0310, -0.0047,  0.0352,  0.0223, -0.0203, -0.0335,  0.0345,\n",
       "                      -0.0045, -0.0171,  0.0179, -0.0305, -0.0260, -0.0085, -0.0096,  0.0353,\n",
       "                       0.0279, -0.0349, -0.0119,  0.0112, -0.0322,  0.0209,  0.0217, -0.0245,\n",
       "                       0.0010, -0.0184,  0.0138,  0.0101,  0.0277, -0.0125, -0.0124,  0.0204,\n",
       "                      -0.0144, -0.0037, -0.0089,  0.0044, -0.0279, -0.0219,  0.0340,  0.0241,\n",
       "                      -0.0011,  0.0196,  0.0298,  0.0313, -0.0008,  0.0203,  0.0282,  0.0214,\n",
       "                       0.0161,  0.0024,  0.0332, -0.0085,  0.0193,  0.0231, -0.0018,  0.0001,\n",
       "                      -0.0084, -0.0321,  0.0210, -0.0318, -0.0188,  0.0268,  0.0258, -0.0029,\n",
       "                      -0.0167, -0.0074, -0.0179, -0.0204, -0.0213, -0.0070, -0.0293, -0.0300,\n",
       "                      -0.0181,  0.0339,  0.0344, -0.0134,  0.0332, -0.0253, -0.0024, -0.0154,\n",
       "                      -0.0319, -0.0275,  0.0328,  0.0050, -0.0009,  0.0061, -0.0251, -0.0024,\n",
       "                      -0.0305, -0.0201, -0.0325, -0.0120,  0.0278,  0.0011,  0.0248,  0.0233,\n",
       "                      -0.0006,  0.0132, -0.0108, -0.0144,  0.0305,  0.0311,  0.0308,  0.0309,\n",
       "                       0.0338,  0.0140, -0.0116, -0.0006, -0.0175,  0.0278, -0.0213,  0.0051,\n",
       "                      -0.0327,  0.0024,  0.0110,  0.0232, -0.0207, -0.0166, -0.0170, -0.0234,\n",
       "                       0.0113, -0.0088, -0.0164, -0.0263, -0.0249, -0.0282,  0.0236,  0.0230,\n",
       "                       0.0272, -0.0018,  0.0312, -0.0261,  0.0340, -0.0256, -0.0111,  0.0131,\n",
       "                      -0.0226,  0.0177, -0.0123, -0.0300,  0.0240, -0.0255, -0.0080, -0.0201,\n",
       "                       0.0344, -0.0026,  0.0018, -0.0234,  0.0105, -0.0324,  0.0327,  0.0180,\n",
       "                       0.0048,  0.0159, -0.0096,  0.0326, -0.0138, -0.0174, -0.0352, -0.0257,\n",
       "                       0.0300,  0.0126,  0.0112, -0.0323,  0.0122,  0.0232,  0.0228, -0.0257,\n",
       "                      -0.0325,  0.0065,  0.0184,  0.0157,  0.0278, -0.0221, -0.0345,  0.0299,\n",
       "                       0.0202, -0.0097,  0.0199,  0.0320, -0.0128, -0.0006, -0.0252, -0.0272,\n",
       "                      -0.0166, -0.0278, -0.0054, -0.0157, -0.0179,  0.0227, -0.0225,  0.0262,\n",
       "                      -0.0286, -0.0032,  0.0026,  0.0052, -0.0212, -0.0143, -0.0234, -0.0136,\n",
       "                       0.0261,  0.0223,  0.0141,  0.0093,  0.0003, -0.0336, -0.0131,  0.0324,\n",
       "                       0.0112, -0.0070,  0.0315, -0.0280,  0.0161, -0.0274, -0.0262, -0.0182,\n",
       "                       0.0022,  0.0190,  0.0016,  0.0238,  0.0320,  0.0169,  0.0024, -0.0207,\n",
       "                       0.0210, -0.0250, -0.0126, -0.0018,  0.0058,  0.0123,  0.0070,  0.0030,\n",
       "                       0.0246,  0.0315,  0.0330,  0.0036,  0.0357, -0.0077,  0.0133, -0.0318,\n",
       "                      -0.0217, -0.0257,  0.0305, -0.0305,  0.0320, -0.0054,  0.0039, -0.0041,\n",
       "                      -0.0205, -0.0169,  0.0190, -0.0071,  0.0223,  0.0271, -0.0333, -0.0222,\n",
       "                      -0.0303, -0.0102,  0.0062,  0.0314, -0.0072, -0.0164, -0.0130,  0.0313,\n",
       "                      -0.0004,  0.0133, -0.0323, -0.0334, -0.0308,  0.0255, -0.0158, -0.0014,\n",
       "                      -0.0027, -0.0062,  0.0289, -0.0132, -0.0275, -0.0275, -0.0259,  0.0085,\n",
       "                       0.0164,  0.0296, -0.0095,  0.0129, -0.0312,  0.0141, -0.0068, -0.0031,\n",
       "                       0.0342, -0.0229, -0.0282, -0.0086,  0.0056,  0.0346,  0.0132, -0.0209,\n",
       "                      -0.0311, -0.0206,  0.0121, -0.0049, -0.0080,  0.0247, -0.0016,  0.0093,\n",
       "                       0.0152,  0.0189,  0.0110, -0.0267, -0.0200,  0.0159, -0.0287, -0.0342,\n",
       "                      -0.0195, -0.0165, -0.0048, -0.0257,  0.0073, -0.0094,  0.0347, -0.0156,\n",
       "                       0.0095, -0.0214,  0.0348, -0.0157, -0.0048, -0.0333,  0.0165,  0.0133,\n",
       "                       0.0327,  0.0328, -0.0344,  0.0189, -0.0102,  0.0095, -0.0262,  0.0074,\n",
       "                       0.0023, -0.0280, -0.0171,  0.0300,  0.0273, -0.0268, -0.0312,  0.0084,\n",
       "                       0.0148,  0.0138, -0.0285,  0.0004, -0.0362, -0.0101, -0.0151, -0.0270,\n",
       "                       0.0237,  0.0267, -0.0190,  0.0126,  0.0069, -0.0219, -0.0186, -0.0317,\n",
       "                       0.0184, -0.0092, -0.0248, -0.0131, -0.0112, -0.0041, -0.0307,  0.0191,\n",
       "                       0.0155, -0.0102,  0.0347,  0.0101,  0.0303, -0.0098,  0.0332,  0.0057,\n",
       "                      -0.0196,  0.0147,  0.0181,  0.0253, -0.0103,  0.0100,  0.0005, -0.0293,\n",
       "                      -0.0196, -0.0148,  0.0077, -0.0247, -0.0212,  0.0156, -0.0116,  0.0340,\n",
       "                       0.0076,  0.0217,  0.0185, -0.0166,  0.0103, -0.0111, -0.0032, -0.0327,\n",
       "                       0.0009, -0.0312,  0.0190, -0.0103,  0.0345,  0.0129,  0.0128,  0.0291,\n",
       "                      -0.0231,  0.0174, -0.0311,  0.0161,  0.0186, -0.0279,  0.0157, -0.0353,\n",
       "                      -0.0213, -0.0260, -0.0052, -0.0157,  0.0048, -0.0202,  0.0326, -0.0051,\n",
       "                      -0.0173, -0.0196, -0.0057, -0.0248])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0480,  0.0225,  0.0399,  ..., -0.0025,  0.0369, -0.0128],\n",
       "                      [ 0.0358,  0.0106, -0.0307,  ...,  0.0090, -0.0041,  0.0302],\n",
       "                      [-0.0282,  0.0032,  0.0140,  ...,  0.0204, -0.0353, -0.0123],\n",
       "                      ...,\n",
       "                      [ 0.0199,  0.0190,  0.0071,  ..., -0.0028, -0.0237,  0.0393],\n",
       "                      [-0.0217, -0.0286, -0.0058,  ...,  0.0041,  0.0259, -0.0144],\n",
       "                      [ 0.0205,  0.0264,  0.0194,  ...,  0.0171, -0.0302, -0.0261]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0572,  0.0038, -0.0125, -0.0045,  0.0235, -0.0279,  0.0098,  0.0334,\n",
       "                       0.0344,  0.0137]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
